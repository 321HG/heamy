{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "\n",
    "np.set_printoptions(precision=6)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "np.random.seed(1000)\n",
    "# logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimalist example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: mean_absolute_error\n",
      "Folds accuracy: [2.5409484630187498, 1.5968722187619016, 1.956704827743762, 1.8927907834120281, 2.7337753076007165, 2.7029209330510935, 1.6230094648637268, 2.5274361322273666, 2.4850130256874818, 2.281401529471093]\n",
      "Mean accuracy: 2.23408726858\n",
      "Standard Deviation: 0.410827978086\n",
      "Variance: 0.168779627578\n"
     ]
    }
   ],
   "source": [
    "# load boston dataset from sklearn\n",
    "data = load_boston()\n",
    "X, y = data['data'], data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=111)\n",
    "\n",
    "# create dataset\n",
    "dataset = Dataset(X_train,y_train,X_test)\n",
    "\n",
    "# initialize RandomForest & LinearRegression \n",
    "model_rf = Regressor(dataset=dataset, estimator=RandomForestRegressor, parameters={'n_estimators': 50},name='rf')\n",
    "model_lr = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "\n",
    "# Stack two models \n",
    "# Returns new dataset with out-of-fold predictions\n",
    "pipeline = ModelsPipeline(model_rf,model_lr)\n",
    "stack_ds = pipeline.stack(k=10,seed=111)\n",
    "\n",
    "# Train LinearRegression on stacked data (second stage)\n",
    "stacker = Regressor(dataset=stack_ds, estimator=LinearRegression)\n",
    "results = stacker.predict()\n",
    "# Validate results using 10 fold cross-validation\n",
    "results = stacker.validate(k=10,scorer=mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Class-based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BostonDataset(1f75270001f1c408a9341958f62cf493)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BostonDataset(Dataset):\n",
    "    def preprocess(self):\n",
    "        data = load_boston()\n",
    "        X, y = data['data'], data['target']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=111)\n",
    "        return X_train, y_train, X_test, y_test\n",
    "BostonDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function-based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boston_dataset(a32eb71bbba4a4ca5e54a13e00b3fd81)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def boston_dataset():\n",
    "    data = load_boston()\n",
    "    X, y = data['data'], data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=111)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "Dataset(preprocessor=boston_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Minimal working example, no cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(c9b316f827981b3d0b53f8ab139234ea)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset(X_train, y_train, X_test)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For models that supports  scikit-learn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegression(34d4a8b31c27c12cbee90430d34f6e38),\n",
       " XGBClassifier(e09a1c5931ad63447f68420beffe1a63))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "linreg = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True})\n",
    "xgbclf = Classifier(dataset=dataset, estimator=XGBClassifier)\n",
    "linreg, xgbclf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function-based  definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlp_model(03860b84c0263516981a901aedbdc1d1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "def mlp_model(X_train, X_test, y_train, y_test=None):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_shape=(X_train.shape[1],)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(output_dim=1, init='glorot_uniform'))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=\"RMSprop\")\n",
    "    model.fit(X_train, y_train.values, nb_epoch=10, batch_size=128, verbose=1,\n",
    "              validation_data=(X_test, y_test.values))\n",
    "    return model.predict(X_test)\n",
    "Regressor(dataset=dataset, estimator=mlp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Class-based definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(3d51fd0fddac221d82f22edb5ecd893c)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLPRegressor(Regressor):\n",
    "    def estimator(self, X_train, X_test, y_train, y_test=None):\n",
    "        # ....\n",
    "        return model.predict(X_test)\n",
    "MLPRegressor(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_rf = Regressor(dataset=dataset, estimator=RandomForestRegressor, parameters={'n_estimators': 50},name='rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: mean_absolute_error\n",
      "Folds accuracy: [2.2178901098901109, 2.0261318681318681, 2.5353626373626379, 2.4249890109890115, 2.3894945054945058]\n",
      "Mean accuracy: 2.31877362637\n",
      "Standard Deviation: 0.178331507546\n",
      "Variance: 0.0318021265837\n"
     ]
    }
   ],
   "source": [
    "res = model_rf.validate(mean_absolute_error,k=5,shuffle=True,stratify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Valditaion using holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: mean_absolute_error\n",
      "Accuracy: 2.18037260752\n"
     ]
    }
   ],
   "source": [
    "# Use randomly sampled 20% of the data as a holdout dataset\n",
    "res = model_rf.validate(mean_absolute_error, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: mean_absolute_error\n",
      "Accuracy: 2.37060240964\n"
     ]
    }
   ],
   "source": [
    "# Custom indices for holdout\n",
    "train_index = np.array(range(250)) \n",
    "test_index = np.array(range(250,333)) \n",
    "\n",
    "res = model_rf.validate(mean_absolute_error,indices=(train_index,test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize pipeline with some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(preprocessor=boston_dataset)\n",
    "\n",
    "model_rf = Regressor(dataset=dataset, estimator=RandomForestRegressor, parameters={'n_estimators': 151},name='rf')\n",
    "model_lr = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "model_knn = Regressor(dataset=dataset, estimator=KNeighborsRegressor, parameters={'n_neighbors': 15},name='knn')\n",
    "\n",
    "pipeline = ModelsPipeline(model_rf, model_lr, model_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (mean_absolute_error): 2.13885516123\n",
      "Best Weights: [ 0.883654  0.116346  0.      ]\n"
     ]
    }
   ],
   "source": [
    "weights = pipeline.find_weights(mean_absolute_error)\n",
    "result = pipeline.weight(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: mean_absolute_error\n",
      "Folds accuracy: [3.3973174238660273, 2.7173869162889996, 2.2419615273624673, 3.0460731991343413, 3.69471451536146, 3.7883397204515954, 2.1306147334648409, 2.9458670951396022, 2.2279531241149551, 2.5849058757589845]\n",
      "Mean accuracy: 2.87751341309\n",
      "Standard Deviation: 0.574079708111\n",
      "Variance: 0.329567511265\n"
     ]
    }
   ],
   "source": [
    "# get predictions for test \n",
    "result = pipeline.mean().execute()\n",
    "# or Validate \n",
    "_ = pipeline.mean().validate(mean_absolute_error,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 28.892009,  29.37481 ,  33.466667,  29.166667,  47.077483,\n",
       "        26.761489,  34.97431 ,  20.713333,  24.627809,  14.088647,\n",
       "        27.172003,  46.706623,  23.34    ,  31.115211,  20.074106,\n",
       "        24.520919,  26.813333,  26.28    ,  19.326667,  22.926667,\n",
       "        14.781457,  27.214832,  22.796856,  32.649007,  16.96    ,\n",
       "        19.510596,  43.784106,  25.313333,  26.133333,  13.452318,\n",
       "        32.067085,  10.633333,  22.453333,  28.96824 ,  44.8     ,\n",
       "        31.2     ,  10.826667,  44.594702,  24.29462 ,  16.87743 ,\n",
       "        27.84    ,  20.377483,  25.1     ,  23.053333,  23.606667,\n",
       "        34.122363,  30.254863,  17.62    ,  43.774834,  20.236077,\n",
       "        23.432906])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipeline.apply(lambda x: np.max(x,axis=0)).execute()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 level stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (mean_absolute_error): 2.04313642617\n",
      "Best Weights: [ 0.356845  0.643155]\n",
      "---\n",
      "Metric: mean_absolute_error\n",
      "Folds accuracy: [2.1941236696859359, 1.6244554310298898, 1.8894005943524717, 2.0743091479239579, 2.4599829226741226, 2.7573855144072361, 1.6437354143971163, 2.333320517625137, 2.2536311445247388, 2.4101536603595477]\n",
      "Mean accuracy: 2.1640498017\n",
      "Standard Deviation: 0.343969088383\n",
      "Variance: 0.118314733763\n"
     ]
    }
   ],
   "source": [
    "# 1st level\n",
    "model_rf = Regressor(dataset=dataset, estimator=RandomForestRegressor, parameters={'n_estimators': 151},name='rf')\n",
    "model_lr = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "model_knn = Regressor(dataset=dataset, estimator=KNeighborsRegressor, parameters={'n_neighbors': 15},name='knn')\n",
    "\n",
    "pipeline = ModelsPipeline(model_rf,model_lr,model_knn)\n",
    "stack_ds = pipeline.stack(k=5,seed=111)\n",
    "\n",
    "# 2nd level\n",
    "stack_rf = Regressor(dataset=stack_ds, estimator=RandomForestRegressor, parameters={'n_estimators': 15},name='rf')\n",
    "stack_lr = Regressor(dataset=stack_ds, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "stack_pipeline = ModelsPipeline(stack_rf,stack_lr)\n",
    "\n",
    "# 3rd level\n",
    "weights = stack_pipeline.find_weights(mean_absolute_error)\n",
    "print('---')\n",
    "result = stack_pipeline.weight(weights).validate(mean_absolute_error,10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
