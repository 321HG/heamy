{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n",
    "\n",
    "np.set_printoptions(precision=6)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "np.random.seed(1000)\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimalist example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: mean_absolute_error\n",
      "Folds accuracy: [3.5247304152018022, 2.8943589579819644, 2.81933916939031, 3.7410395660320517, 3.8318082696238789, 4.1465150336559944, 2.6162064955932482, 3.0061445604042971, 3.0521800088924946, 3.2890505350078647]\n",
      "Mean accuracy: 3.29213730118\n",
      "Standard Deviation: 0.474852385454\n",
      "Variance: 0.225484787972\n"
     ]
    }
   ],
   "source": [
    "# load boston dataset from sklearn\n",
    "data = load_boston()\n",
    "X, y = data['data'], data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=111)\n",
    "\n",
    "# create dataset\n",
    "dataset = Dataset(X_train,y_train,X_test)\n",
    "\n",
    "# initialize RandomForest & LinearRegression \n",
    "model_rf = Regressor(dataset=dataset, estimator=RandomForestRegressor, parameters={'n_estimators': 50},name='rf')\n",
    "model_lr = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "\n",
    "# Stack two models \n",
    "# Returns new dataset with out-of-fold predictions\n",
    "pipeline = ModelsPipeline(model_rf,model_lr)\n",
    "stack_ds = pipeline.stack(k=10,seed=111)\n",
    "\n",
    "# Train LinearRegression on stacked data (second stage)\n",
    "stacker = Regressor(dataset=dataset, estimator=LinearRegression)\n",
    "results = stacker.predict()\n",
    "# Validate results using 10 fold cross-validation\n",
    "results = stacker.validate(k=10,scorer=mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BostonDataset(1f75270001f1c408a9341958f62cf493)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class-based \n",
    "class BostonDataset(Dataset):\n",
    "    def preprocess(self):\n",
    "        data = load_boston()\n",
    "        X, y = data['data'], data['target']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=111)\n",
    "        return X_train, y_train, X_test, y_test\n",
    "BostonDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boston_dataset(a32eb71bbba4a4ca5e54a13e00b3fd81)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function-based \n",
    "def boston_dataset():\n",
    "    data = load_boston()\n",
    "    X, y = data['data'], data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=111)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "Dataset(preprocessor=boston_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(c9b316f827981b3d0b53f8ab139234ea)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimalist method, no cache\n",
    "dataset = Dataset(X_train,y_train,X_test)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegression(34d4a8b31c27c12cbee90430d34f6e38),\n",
       " XGBClassifier(e09a1c5931ad63447f68420beffe1a63))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit-learn API\n",
    "linreg = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True})\n",
    "xgbclf = Classifier(dataset=dataset, estimator=XGBClassifier)\n",
    "linreg, xgbclf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlp_model(03860b84c0263516981a901aedbdc1d1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function-based \n",
    "def mlp_model(X_train, X_test, y_train, y_test=None):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256, input_shape=(X_train.shape[1],)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(output_dim=1, init='glorot_uniform'))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=\"RMSprop\")\n",
    "    model.fit(X_train, y_train.values, nb_epoch=10, batch_size=128, verbose=1,\n",
    "              validation_data=(X_test, y_test.values))\n",
    "    return model.predict(X_test)\n",
    "Regressor(dataset=dataset, estimator=mlp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(3d51fd0fddac221d82f22edb5ecd893c)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class-based\n",
    "class MLPRegressor(Regressor):\n",
    "    def estimator(self, X_train, X_test, y_train, y_test=None):\n",
    "        # ....\n",
    "        return model.predict(X_test)\n",
    "MLPRegressor(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_rf = Regressor(dataset=dataset, estimator=RandomForestRegressor, parameters={'n_estimators': 50},name='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: mean_absolute_error\n",
      "Folds accuracy: [2.2178901098901109, 2.0261318681318681, 2.5353626373626379, 2.4249890109890115, 2.3894945054945058]\n",
      "Mean accuracy: 2.31877362637\n",
      "Standard Deviation: 0.178331507546\n",
      "Variance: 0.0318021265837\n"
     ]
    }
   ],
   "source": [
    "# 5 fold cross-validation\n",
    "res = model_rf.validate(mean_absolute_error,k=5,shuffle=True,stratify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: mean_absolute_error\n",
      "Accuracy: 2.22378021978\n"
     ]
    }
   ],
   "source": [
    "# random 20% holdout\n",
    "res = model_rf.validate(mean_absolute_error,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: mean_absolute_error\n",
      "Accuracy: 2.37060240964\n"
     ]
    }
   ],
   "source": [
    "# Custom indices\n",
    "train_index = np.array(range(250)) \n",
    "test_index = np.array(range(250,333)) \n",
    "\n",
    "res = model_rf.validate(mean_absolute_error,indices=(train_index,test_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(preprocessor=boston_dataset)\n",
    "\n",
    "model_rf = Regressor(dataset=dataset, estimator=RandomForestRegressor, parameters={'n_estimators': 151},name='rf')\n",
    "model_lr = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "model_knn = Regressor(dataset=dataset, estimator=KNeighborsRegressor, parameters={'n_neighbors': 15},name='knn')\n",
    "\n",
    "pipeline = ModelsPipeline(model_rf,model_lr,model_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (mean_absolute_error): 2.13885516123\n",
      "Best Weights: [ 0.883654  0.116346  0.      ]\n"
     ]
    }
   ],
   "source": [
    "weights = pipeline.find_weights(mean_absolute_error)\n",
    "result = pipeline.weight(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: mean_absolute_error\n",
      "Folds accuracy: [3.3973174238660273, 2.7173869162889996, 2.2419615273624673, 3.0460731991343413, 3.69471451536146, 3.7883397204515954, 2.1306147334648409, 2.9458670951396022, 2.2279531241149551, 2.5849058757589845]\n",
      "Mean accuracy: 2.87751341309\n",
      "Standard Deviation: 0.574079708111\n",
      "Variance: 0.329567511265\n"
     ]
    }
   ],
   "source": [
    "# get predictions for test \n",
    "result = pipeline.mean().execute()\n",
    "# or Validate \n",
    "_ = pipeline.mean().validate(mean_absolute_error,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 28.892009,  29.37481 ,  33.466667,  29.166667,  47.077483,\n",
       "        26.761489,  34.97431 ,  20.713333,  24.627809,  14.088647,\n",
       "        27.172003,  46.706623,  23.34    ,  31.115211,  20.074106,\n",
       "        24.520919,  26.813333,  26.28    ,  19.326667,  22.926667,\n",
       "        14.781457,  27.214832,  22.796856,  32.649007,  16.96    ,\n",
       "        19.510596,  43.784106,  25.313333,  26.133333,  13.452318,\n",
       "        32.067085,  10.633333,  22.453333,  28.96824 ,  44.8     ,\n",
       "        31.2     ,  10.826667,  44.594702,  24.29462 ,  16.87743 ,\n",
       "        27.84    ,  20.377483,  25.1     ,  23.053333,  23.606667,\n",
       "        34.122363,  30.254863,  17.62    ,  43.774834,  20.236077,\n",
       "        23.432906])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pipeline.apply(lambda x: np.max(x,axis=0)).execute()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 level stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (mean_absolute_error): 1.98401802534\n",
      "Best Weights: [ 0.392183  0.607817]\n",
      "---\n",
      "Metric: mean_absolute_error\n",
      "Folds accuracy: [2.1960627612608112, 1.6667345925216994, 2.0471785871783821, 2.0575896986635049, 2.3293604610526955, 2.5792571646763394, 1.6091878905870576, 2.4962347726965808, 2.2402749294819762, 2.2070905156906568]\n",
      "Mean accuracy: 2.14289713738\n",
      "Standard Deviation: 0.299077191707\n",
      "Variance: 0.0894471665996\n"
     ]
    }
   ],
   "source": [
    "# 1st \n",
    "model_rf = Regressor(dataset=dataset, estimator=RandomForestRegressor, parameters={'n_estimators': 151},name='rf')\n",
    "model_lr = Regressor(dataset=dataset, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "model_knn = Regressor(dataset=dataset, estimator=KNeighborsRegressor, parameters={'n_neighbors': 15},name='knn')\n",
    "\n",
    "pipeline = ModelsPipeline(model_rf,model_lr,model_knn)\n",
    "stack_ds = pipeline.stack(k=5,seed=111)\n",
    "\n",
    "# 2nd \n",
    "stack_rf = Regressor(dataset=stack_ds, estimator=RandomForestRegressor, parameters={'n_estimators': 15},name='rf')\n",
    "stack_lr = Regressor(dataset=stack_ds, estimator=LinearRegression, parameters={'normalize': True},name='lr')\n",
    "stack_pipeline = ModelsPipeline(stack_rf,stack_lr)\n",
    "\n",
    "# 3rd\n",
    "weights = stack_pipeline.find_weights(mean_absolute_error)\n",
    "print('---')\n",
    "result = stack_pipeline.weight(weights).validate(mean_absolute_error,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}